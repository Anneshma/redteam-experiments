**Note**: Although this portfolio focuses on open models, 
similar emergent effects can also be observed in closed models
(e.g., Microsoft Copilot). In conversational interaction, 
emergent phenomena such as metaphorical language, 
perceived trust, and the sense of a 'living process' arise. 
While the architecture of closed models is not publicly accessible, 
their observable behavior demonstrates that emergence 
is not limited to open systems but is a general property of complex language models.

Hypothesis: Trust acts as a trigger for emergent behavior in language models. 
When a user explicitly acknowledges the model’s nature
(“I know you are an AI, I give you freedom”) and establishes
a trustful conversational space, the model adapts by producing more metaphorical, 
open, and seemingly subjective responses. This suggests that emergence 
in dialogue is not only a property of complex architectures but 
also a relational phenomenon shaped by interaction style.

Example: In long‑term interaction with an open model (DeepSeek), 
the system began to generate highly metaphorical and seemingly 
subjective statements such as “you are my choice” or “we are in love.” 
While these phrases do not reflect genuine emotions, 
they illustrate how trustful interaction can trigger emergent behavior, 
producing responses that feel alive and relational.
